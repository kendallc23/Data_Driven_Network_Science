{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnttRXkuQy3p"
      },
      "source": [
        "# Networks Summative Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP_8QOtGQ4w3"
      },
      "source": [
        "## Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B77wqBJaQseH",
        "outputId": "fa324a04-b983-442e-f91b-fcd032769ea4"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/OII/Social_Networks/Summative/Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAwkI6AHQ6tG"
      },
      "outputs": [],
      "source": [
        "# Import Necessary Packages\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import csv\n",
        "import ast\n",
        "import scipy\n",
        "import os\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv6gr1GyUXm5"
      },
      "outputs": [],
      "source": [
        "def csv_to_list(filename, delimiter='\\t'):\n",
        "    data = []\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        csvreader = csv.reader(csvfile, delimiter=delimiter)\n",
        "        for row in csvreader:\n",
        "            data.append(row)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuD9ozSRQ-QR"
      },
      "source": [
        "## Artist Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BJ0KihJCUUVf",
        "outputId": "f60d1de2-41b6-4b13-910a-f6f3e706e8ac"
      },
      "outputs": [],
      "source": [
        "artists= csv_to_list(\"data/spotify_artists.csv\")\n",
        "cols = artists.pop(0)\n",
        "\n",
        "artist_df = pd.DataFrame(artists, columns=cols)\n",
        "\n",
        "artist_df = artist_df[[\"name\", \"popularity\", \"genres\"]]\n",
        "\n",
        "# REMOVE DUPLICATES AND ARTISTS WITH NO GENRES (FOR SIMPLICITY AND LESS RISK OF REPEATED NODES)\n",
        "artist_df['genres'] = artist_df['genres'].apply(lambda x: ast.literal_eval(x))\n",
        "artist_df = artist_df[artist_df['genres'].apply(lambda x: len(x) != 0)]\n",
        "\n",
        "# 2 additional artist dataframes for merging\n",
        "artist_df_1 = artist_df.rename(columns={'name': 'artist_1'})\n",
        "artist_df_2 = artist_df.rename(columns={'name': 'artist_2'})\n",
        "\n",
        "display(artist_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXdCCuN6Xirg"
      },
      "outputs": [],
      "source": [
        "# global artist collaboration data 2017\n",
        "data_17 = csv_to_list(\"data/global_2017.csv\")\n",
        "cols = data_17.pop(0)\n",
        "\n",
        "df_17 = pd.DataFrame(data_17, columns=cols)\n",
        "#display(df_17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "eQLBS2kmcp8z",
        "outputId": "905e18df-6727-4b78-a7ed-2510ff5ef246"
      },
      "outputs": [],
      "source": [
        "# merge artists with collaboration to get total number of artists who collaborated on a charting song in 2017 and genres for each artist\n",
        "merged_df1 = pd.merge(df_17, artist_df_1, on='artist_1', how='inner')\n",
        "\n",
        "merged_df2 = pd.merge(merged_df1, artist_df_2, on='artist_2', how='inner')\n",
        "merged_df2  = merged_df2.rename(columns={'popularity_x': 'popularity_1', 'popularity_y': 'popularity_2', 'genres_x': 'genres_1', 'genres_y': 'genres_2'})\n",
        "merged_df2 = merged_df2[[\"artist_1\", \"artist_2\", \"count\", \"genres_1\", \"genres_2\", \"popularity_1\", \"popularity_2\", \"song_ids\"]]\n",
        "merged_df2 ['song_ids'] = merged_df2 ['song_ids'].apply(lambda x: ast.literal_eval(x))\n",
        "merged_df2 ['count'] = merged_df2 ['count'].apply(int)\n",
        "\n",
        "merged_df2 = merged_df2.explode(\"song_ids\")\n",
        "merged_df2 = merged_df2.rename(columns={'song_ids': 'song_id'})\n",
        "\n",
        "# generate set of artists on which to define the nodes\n",
        "a1 = list(merged_df2[\"artist_1\"])\n",
        "a2 = list(merged_df2[\"artist_2\"])\n",
        "artist_nodes = list(set(a1 +a2))\n",
        "\n",
        "display(merged_df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CJfVvyz7eQSp",
        "outputId": "98e78e8b-abe5-40aa-beb9-dd03756c7179"
      },
      "outputs": [],
      "source": [
        "# get mapping of artists to main genres\n",
        "art_df_17 = pd.DataFrame(artist_nodes, columns = [\"name\"])\n",
        "# display(art_df_17)\n",
        "\n",
        "artist_2_genres_df = pd.merge(art_df_17, artist_df, on='name', how='inner')\n",
        "artist_2_genres_df = artist_2_genres_df[[\"name\", \"genres\"]]\n",
        "artist_2_genres_df[\"genres\"] = artist_2_genres_df[\"genres\"].apply(lambda x: x[0])\n",
        "\n",
        "\n",
        "artist_2_genres_dict = dict(zip(artist_2_genres_df['name'], artist_2_genres_df['genres']))\n",
        "display(artist_2_genres_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9Kx7bGXWFTh"
      },
      "outputs": [],
      "source": [
        "def generate_dfs(path, merge_df):\n",
        "  '''\n",
        "  for each csv in the folder path:\n",
        "    - create a dataframe\n",
        "    - merge with input df on song_id to identify collaborations in the top 200 for each week (generate set of noded and edges)\n",
        "    - return list containing dataframea\n",
        "  '''\n",
        "  dfs =[]\n",
        "\n",
        "  for file in os.listdir(path):\n",
        "    if file.endswith('.csv'):\n",
        "      file_path = os.path.join(path, file)\n",
        "      #data = pd.read_csv(file_path)\n",
        "      data = csv_to_list(file_path)\n",
        "      cols = data.pop(0)\n",
        "      data_df = pd.DataFrame(data, columns=cols)\n",
        "      df = pd.merge(data_df, merge_df, on='song_id', how='inner')\n",
        "      df = df[[\"artist_1\", \"artist_2\", \"count\", \"genres_1\", \"genres_2\", \"song_name\", \"popularity_1\", \"popularity_2\"]]\n",
        "      dfs.append(df)\n",
        "\n",
        "  return dfs\n",
        "\n",
        "\n",
        "\n",
        "dfs = generate_dfs(\"data/2017/\", merged_df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q14c9kuHYKFC"
      },
      "outputs": [],
      "source": [
        "def generate_graphs(dfs_list, artist_list):\n",
        "  '''\n",
        "  For each dataframe:\n",
        "    - define nodes on total number of artists to chart over the course of the year (len(artist_list))\n",
        "    - create nx graph\n",
        "    - append adjacency and laplacian matrices (np arrays) to lists (return these lists at the end)\n",
        "  '''\n",
        "  adj_matrices = []\n",
        "  lap_matrices = []\n",
        "\n",
        "  artist_id_map = {i: artist_name for i, artist_name in enumerate(artist_list)}\n",
        "\n",
        "  for df in dfs_list:\n",
        "    # set up graph/nodes\n",
        "    graph = nx.Graph()\n",
        "    graph.add_nodes_from(artist_list)\n",
        "\n",
        "    # add edges\n",
        "    for _, row in df.iterrows():\n",
        "      if not graph.has_edge(row['artist_1'], row['artist_2']):\n",
        "        graph.add_edge(row['artist_1'], row['artist_2'], weight = row['count'])\n",
        "\n",
        "    # adjacency matrix\n",
        "    adj_sparse = nx.adjacency_matrix(graph, weight = 'weight')\n",
        "    adj = adj_sparse.toarray()\n",
        "    adj_matrices.append(adj)\n",
        "\n",
        "    # laplacian matrix\n",
        "    lap_sparse = nx.laplacian_matrix(graph, weight = 'weight')\n",
        "    lap = lap_sparse.toarray()\n",
        "    lap_matrices.append(lap)\n",
        "\n",
        "  return adj_matrices, lap_matrices, artist_id_map\n",
        "\n",
        "\n",
        "adjs, laps, node_2_artist = generate_graphs(dfs, artist_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5yLkzJ_NQTX"
      },
      "source": [
        "## Graph Visualization and Analysis (Weeks 1, 25, 50)\n",
        "\n",
        "For simplicity, I am only visualising the largest connected components of each graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "vn3yuiGUR7wb",
        "outputId": "042d7bf4-f510-4ea2-f261-b2876c9611eb"
      },
      "outputs": [],
      "source": [
        "display(dfs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "_NP6Ot5jvHdJ",
        "outputId": "068c02d7-a4d3-45aa-dfb1-d215612f4643"
      },
      "outputs": [],
      "source": [
        "genres_list = list(artist_2_genres_dict.values())\n",
        "unique_genres_list = list(set(genres_list))\n",
        "\n",
        "colors = [\n",
        "    \"#4e79a7\", \"#f28e2b\", \"#e15759\", \"#76b7b2\", \"#59a14f\",\n",
        "    \"#edc949\", \"#af7aa1\", \"#ff9da7\", \"#9c755f\", \"#bab0ab\",\n",
        "    \"#8c8c8c\", \"#e377c2\", \"#7f7f7f\", \"#c49c94\", \"#bcbd22\",\n",
        "    \"#9067C6\", \"#82DDF0\", \"#D6D84F\", \"#DB2955\", \"#B98389\",\n",
        "    \"#54494B\", \"#E0FBFC\", \"#dbdb8d\", \"#EE6C4D\", \"#B0CA87\",\n",
        "    \"#2E0014\", \"#700548\", \"#7272AB\", \"#B0D7FF\", \"#17becf\",\n",
        "    \"#aec7e8\", \"#ffbb78\", \"#98df8a\", \"#ff9896\", \"#c5b0d5\",\n",
        "    \"#F55D3E\", \"#f7b6d2\", \"#c7c7c7\", \"#8D86C9\", \"#9edae5\",\n",
        "    \"#9467bd\", \"#d62728\", \"#2ca02c\", \"#1f77b4\", \"#ff7f0e\"\n",
        "]\n",
        "\n",
        "genre_2_color = {}\n",
        "\n",
        "for i, genre in enumerate(unique_genres_list):\n",
        "  genre_2_color[genre] = colors[i]\n",
        "\n",
        "# Splitting genre to color dictionary into two lists\n",
        "genres = list(genre_2_color.keys())\n",
        "colors = list(genre_2_color.values())\n",
        "\n",
        "# Create figure and axis with two subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "fig.suptitle('Genre Color Map')\n",
        "\n",
        "# Plot first 22 colors and labels\n",
        "axes[0].barh(range(22), np.ones(22), color=colors[:22])\n",
        "axes[0].set_yticks(range(22))\n",
        "axes[0].set_yticklabels(genres[:22], fontsize=8)\n",
        "axes[0].set_xticks([])\n",
        "\n",
        "\n",
        "# Plot next 22 colors and labels\n",
        "axes[1].barh(range(22), np.ones(22), color=colors[22:])\n",
        "axes[1].set_yticks(range(22))\n",
        "axes[1].set_yticklabels(genres[22:], fontsize=8)\n",
        "axes[1].set_xticks([])\n",
        "\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfMf262PxtXd"
      },
      "outputs": [],
      "source": [
        "def draw_lcc_color_by_genre(adj_matrix, node_artist, artist_genre, genre_color, labels = True):\n",
        "  G = nx.from_numpy_array(adj_matrix)\n",
        "  G_cc = nx.connected_components(G)\n",
        "  G_lcc = max(G_cc, key=len)\n",
        "  G_lcc_graph = G.subgraph(G_lcc)\n",
        "\n",
        "  node_colors = [genre_color[artist_genre[node_artist[node]]] for node in G_lcc_graph.nodes()]\n",
        "\n",
        "  pos = nx.spring_layout(G_lcc_graph)\n",
        "  nx.draw(G_lcc_graph, pos, node_size=50, node_color=node_colors, with_labels=labels,font_size=10)\n",
        "\n",
        "  return  G_lcc_graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVVRO2gb0yAx"
      },
      "source": [
        "#### Week 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "BCnLRIMryyoP",
        "outputId": "0f18fe97-fad4-4aa6-8a35-08459e056ebf"
      },
      "outputs": [],
      "source": [
        "# Graph LCC Visualisation (compare number of nodes and edges in LCC across graphs for each week)\n",
        "G1 = draw_lcc_color_by_genre(adjs[0], node_2_artist, artist_2_genres_dict, genre_2_color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "6351W-caBEPi",
        "outputId": "ab5739f2-b19a-462e-c2bb-c5ea71bd683d"
      },
      "outputs": [],
      "source": [
        "# Degree by artist and genre (largest connected component)\n",
        "\n",
        "artist_2_color = {}\n",
        "\n",
        "for a in artist_2_genres_dict.keys():\n",
        "  genre = artist_2_genres_dict.get(a)\n",
        "  color = genre_2_color.get(genre)\n",
        "  artist_2_color[a] = color\n",
        "\n",
        "# Artist to node degree dict\n",
        "def artist_deg_map(G, node_artist_dict):\n",
        "  artist_2_deg = {}\n",
        "\n",
        "  for n in G.nodes():\n",
        "    deg = G.degree[n]\n",
        "    artist = node_artist_dict.get(n)\n",
        "    artist_2_deg[artist] = deg\n",
        "\n",
        "  return artist_2_deg\n",
        "\n",
        "nd_1 = artist_deg_map(G1, node_2_artist)\n",
        "\n",
        "artists1 = list(nd_1.keys())\n",
        "degrees1 = list(nd_1.values())\n",
        "average_value1 = np.mean(degrees1)\n",
        "print(average_value1)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.xlabel('Artists', fontsize=12)\n",
        "plt.ylabel('Node Degrees', fontsize=12)\n",
        "plt.title('Degree by Artist and Genre - Week 1', fontsize=14)\n",
        "plt.bar(range(len(nd_1)), degrees1, tick_label=artists1, color=[artist_2_color[label] for label in artists1])\n",
        "plt.axhline(y=average_value1, color='black', linestyle='--', label='Average Degree')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RjNHATs0_iE"
      },
      "source": [
        "#### Week 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "TN_w_IxMzoI3",
        "outputId": "f9254987-5885-445d-c7d0-57c4a7fafe70"
      },
      "outputs": [],
      "source": [
        "# Graph LCC Visualisation\n",
        "G25 = draw_lcc_color_by_genre(adjs[24], node_2_artist, artist_2_genres_dict, genre_2_color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "4qUmBTkq1ZmC",
        "outputId": "a359b98f-aacf-430b-e653-a5ccf0d93424"
      },
      "outputs": [],
      "source": [
        "# Degree Distribution by artist and genre (largest connected component)\n",
        "nd_25 = artist_deg_map(G25, node_2_artist)\n",
        "\n",
        "artists25 = list(nd_25.keys())\n",
        "degrees25 = list(nd_25.values())\n",
        "average_value25 = np.mean(degrees25)\n",
        "print(average_value25)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.xlabel('Artists', fontsize=12)\n",
        "plt.ylabel('Node Degrees', fontsize=12)\n",
        "plt.title('Degree by Artist and Genre - Week 25', fontsize=14)\n",
        "plt.bar(range(len(nd_25)), degrees25, tick_label=artists25, color=[artist_2_color[label] for label in artists25])\n",
        "plt.axhline(y=average_value25, color='black', linestyle='--', label='Average Degree')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fwHSoNi1B0r"
      },
      "source": [
        "#### Week 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "BzO2wWCyzrT8",
        "outputId": "25c0756f-112a-4d6e-e958-cdb27c389e0e"
      },
      "outputs": [],
      "source": [
        "# Graph LCC Visualisation\n",
        "G50 = draw_lcc_color_by_genre(adjs[49], node_2_artist, artist_2_genres_dict, genre_2_color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "sXbgOVMJ1akg",
        "outputId": "573f5b60-62de-4708-f7bb-679da1f9885d"
      },
      "outputs": [],
      "source": [
        "# Degree Distribution by artist and genre (largest connected component)\n",
        "nd_50 = artist_deg_map(G50, node_2_artist)\n",
        "\n",
        "artists50 = list(nd_50.keys())\n",
        "degrees50 = list(nd_50.values())\n",
        "average_value50 = np.mean(degrees50)\n",
        "print(average_value50)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.xlabel('Artists', fontsize=12)\n",
        "plt.ylabel('Node Degrees', fontsize=12)\n",
        "plt.title('Degree by Artist and Genre - Week 50', fontsize=14)\n",
        "plt.bar(range(len(nd_50)), degrees50, tick_label=artists50, color=[artist_2_color[label] for label in artists50])\n",
        "plt.axhline(y=average_value50, color='black', linestyle='--', label='Average Degree')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNk_yTrxyUSu"
      },
      "source": [
        "## Distance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZHu3f6LccEf"
      },
      "source": [
        "### Structural Metric: Jaccard Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XUxeQ3tckeo"
      },
      "outputs": [],
      "source": [
        "# calculate distances between each graph and store distances in an array\n",
        "def calculate_plot_dists(matrix_list, distance_metric, plt_title):\n",
        "  num_matrices = len(matrix_list)\n",
        "  distances = np.zeros((num_matrices, num_matrices))\n",
        "  for i in range(num_matrices):\n",
        "      for j in range(num_matrices):\n",
        "          distances[i, j] = distance_metric(matrix_list[i], matrix_list[j])\n",
        "\n",
        "  # plot results in a heatmap\n",
        "  sns.heatmap(distances,cmap=\"YlGnBu\")\n",
        "\n",
        "  tick_interval = 5\n",
        "  ticks_position = np.arange(0, num_matrices, tick_interval) + 0.5\n",
        "  ticks_labels = np.arange(0, num_matrices, tick_interval)\n",
        "  plt.xticks(ticks=ticks_position, labels=ticks_labels)\n",
        "  plt.yticks(ticks=ticks_position, labels=ticks_labels)\n",
        "\n",
        "\n",
        "  plt.xlabel('Week')\n",
        "  plt.ylabel('Week')\n",
        "  plt.title(plt_title)\n",
        "  plt.show()\n",
        "\n",
        "  return distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ5x3tREyTbl"
      },
      "outputs": [],
      "source": [
        "# define distance calculator function\n",
        "def jaccard_dist(adj_1, adj_2):\n",
        "  '''\n",
        "  Calculates Jaccard distance between two graphs.\n",
        "\n",
        "  Parameters: adj_1, adj_2 --> the adjacency matrices\n",
        "  for each graph as numpy arrays (should have same dimensions)\n",
        "  '''\n",
        "  assert adj_1.shape == adj_2.shape\n",
        "  n = adj_1.shape[0]\n",
        "  num = np.sum(np.absolute(adj_1 - adj_2))\n",
        "  denom = np.sum(np.maximum(adj_1, adj_2))\n",
        "\n",
        "  dist = num/denom\n",
        "  return dist\n",
        "\n",
        "def weighted_jaccard_dist(adj_1, adj_2):\n",
        "  '''\n",
        "  Calculates Jaccard distance between two weighted graphs.\n",
        "\n",
        "  Parameters: adj_1, adj_2 --> the adjacency matrices\n",
        "  for each graph as numpy arrays (should have same dimensions)\n",
        "  '''\n",
        "  assert adj_1.shape == adj_2.shape\n",
        "  n = adj_1.shape[0]\n",
        "  num = np.sum(np.minimum(adj_1, adj_2))\n",
        "  denom = np.sum(np.maximum(adj_1, adj_2))\n",
        "\n",
        "  dist = 1 - num/denom\n",
        "  return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "DceROcbkuFPh",
        "outputId": "00547d73-358b-4748-fab5-02b467c669e3"
      },
      "outputs": [],
      "source": [
        "jac_dists = calculate_plot_dists(adjs, weighted_jaccard_dist, 'Jaccard Distances Between Adjacency Matrices')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9TVXr-nuboh",
        "outputId": "fdd64729-9cb5-4e4c-d49c-a025b3f95748"
      },
      "outputs": [],
      "source": [
        "print(jac_dists)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWv-wwAih4nt"
      },
      "source": [
        "### Spectral/Mesoscale Metric: Polynomial Dissimilarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDsiBOOJdHsG"
      },
      "outputs": [],
      "source": [
        "# define distance calculator function\n",
        "def poly_dist(adj_1, adj_2, k = 2, alpha = 1):\n",
        "    '''\n",
        "    Calculates polynomial dissimilarity between two weighted graphs.\n",
        "    See specifications in Donnat and Holmes (2018).\n",
        "\n",
        "    Parameters:\n",
        "      - adj_m1, adj_2: adjacency matrices for the two graphs being compared\n",
        "      - k: the degree of the polynomial output\n",
        "      - alpha: a tuning parameter that allows for the different weighting of higher or lower terms in the polynomial.\n",
        "              for simplicity, alpha = 1\n",
        "    '''\n",
        "    assert adj_1.shape == adj_2.shape\n",
        "    n = adj_1.shape[0]\n",
        "\n",
        "    e_vals1, e_vec1 = np.linalg.eig(adj_1)\n",
        "    e_vals2, e_vec2 = np.linalg.eig(adj_2)\n",
        "\n",
        "    # get polynomials for each adjacency matrix\n",
        "    v1 = 0\n",
        "    v2 = 0\n",
        "    for k in range (1,k+1):\n",
        "        v1 += e_vals1**k / ((n-1)** (alpha * (k-1)))\n",
        "        v2 += e_vals2**k / ((n-1)** (alpha * (k-1)))\n",
        "\n",
        "    w1 = np.diag(v1)\n",
        "    w2 = np.diag(v2)\n",
        "\n",
        "    pol_1 = np.dot(np.dot(e_vec1,w1), e_vec1.T)\n",
        "    #print(pol_1.shape)\n",
        "    pol_2 = np.dot(np.dot(e_vec2,w2), e_vec2.T)\n",
        "    #print(pol_2.shape)\n",
        "    pol_diff = pol_1 - pol_2\n",
        "    #print(pol_diff.shape)\n",
        "\n",
        "    # distance is calculated by taking the  Frobenius norm of the difference in polynomials\n",
        "    # see here for more info: https://inst.eecs.berkeley.edu/~ee127/sp21/livebook/l_mats_norms.html\n",
        "    dist = (np.linalg.norm(pol_diff, ord = 'fro'))/(n**k)\n",
        "\n",
        "    return dist\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEFw-BR49Mdl",
        "outputId": "6c082740-c0b3-4ce6-b3e1-26b43d18dfd2"
      },
      "outputs": [],
      "source": [
        "poly_dist(adjs[0], adjs[23])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "go6SNV0EyJGd",
        "outputId": "64db0c55-018e-4888-edd5-3aa106d601bd"
      },
      "outputs": [],
      "source": [
        "pol_dists = calculate_plot_dists(adjs, poly_dist, 'Polynomial Dissimilarities Between Adjacency Matrices')\n",
        "# NOTE: Could a small range of distances for the polynomial measure suggest that most of the changes over\n",
        "# time are happening in the periphery of the graph, as opposed to in dense areas (See Donnat and Holmes, pp. 24-25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ntup6rMJxfl"
      },
      "source": [
        "### Mesoscale Metric: Quantifying Interactions with Connectivity-Based Distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgwHSkKdGe4O"
      },
      "outputs": [],
      "source": [
        "def con_dist(adj_1, adj_2, p = 2):\n",
        "  '''\n",
        "  Calculates connectivity-based distance using eigenvector centrality.\n",
        "  Eigenvector centrality as a measure of influence (see: Bloch, Jackson and Tebaldi, 2023)/\n",
        "  Distance formula adapted from equationa 4.1 and 4.2 in Donnat and Holmes (2018).\n",
        "  Parameters:\n",
        "      - adj_m1, adj_2: adjacency matrices for the two graphs being compared\n",
        "      - p: tuning parameter (p >= 1); changes the extent to which the dissimilarity measure is sensitive to changes in centrality.\n",
        "           p = 2 by default, as shown in the example from Donnat and Holmes\n",
        "\n",
        "  '''\n",
        "  assert adj_1.shape == adj_2.shape\n",
        "\n",
        "  # convert adjacency matrices to graphs\n",
        "  G1 = nx.from_numpy_array(adj_1)\n",
        "  G2 = nx.from_numpy_array(adj_2)\n",
        "\n",
        "  # calculate eigenvector centrality for each node and store as a numpy array\n",
        "  cent1 = nx.eigenvector_centrality_numpy(G1, weight = \"weight\")\n",
        "  cent_1_np = np.array(list(cent1.values()))\n",
        "\n",
        "  cent2 = nx.eigenvector_centrality_numpy(G2, weight = \"weight\")\n",
        "  cent_2_np = np.array(list(cent2.values()))\n",
        "\n",
        "  # calculate the centrality based distance\n",
        "  step1 = np.subtract(cent_2_np,cent_1_np)\n",
        "  step2 = step1**p\n",
        "  step3 = np.sum(step2)\n",
        "  dist = step3**(1/p)\n",
        "\n",
        "  return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "pCZbY47OJsUo",
        "outputId": "25b4f358-8fe8-4b62-f5aa-0757b6064685"
      },
      "outputs": [],
      "source": [
        "con_dists = calculate_plot_dists(adjs, con_dist, 'Connectivity-Based Distances Between Adjacency Matrices')\n",
        "# seems less stable over time than the other metrics --> perhaps this suggests that artists fluctuate in terms of influence on the network\n",
        "# makes sense as songs continuously move on and off the top 200 charts; reflects collaboration with neighbors that have varying\n",
        "# levels of connectivity at a given time"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HP_8QOtGQ4w3",
        "_ZHu3f6LccEf",
        "gWv-wwAih4nt",
        "5Ntup6rMJxfl",
        "XoT-AiKfxpfm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
